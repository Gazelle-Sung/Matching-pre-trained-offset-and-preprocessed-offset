# Matching-pre-trained-word-embedding-offset-to-preprocessed-token-offset
This is a project to match the offset of the pre-trained word embeddings such as BERT, ELMo, and Glove to the preprocessed token offset and its dependencies in various ways of preprocessing method such as Stanza and Spacy. Therefore, the result of this can be applied to the graph neural networks without concern of its mismatch of the preprocessed token offset and pre-trained result offset.

# Installation of preprocessing pipelines
1. Stanza: https://stanfordnlp.github.io/stanza/#getting-started
2. Spacy: https://spacy.io/usage

